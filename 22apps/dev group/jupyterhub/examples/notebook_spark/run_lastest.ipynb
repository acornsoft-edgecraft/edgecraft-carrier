{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sparkConf = pyspark.SparkConf()\n",
    "sparkConf.setMaster(\"k8s://https://kubernetes.default:443\")\n",
    "sparkConf.setAppName(\"spark-test\")\n",
    "sparkConf.set(\"spark.submit.deployMode\", \"client\")\n",
    "sparkConf.set(\"spark.kubernetes.container.image\", \"tarrantro/spark-py:v3.0.1\")  # change that to uour pyspark image\n",
    "#sparkConf.set(\"spark.kubernetes.container.image.pullPolicy\", \"IfNotPresent\")\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.caCertFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\")\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.oauthTokenFile\", \"/var/run/secrets/kubernetes.io/serviceaccount/token\")\n",
    "sparkConf.set(\"spark.kubernetes.namespace\", \"spark\")\n",
    "sparkConf.set(\"spark.kubernetes.pyspark.pythonVersion\", \"3\")\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n",
    "sparkConf.set(\"spark.kubernetes.authenticate.serviceAccountName\", \"spark\")\n",
    "sparkConf.set(\"spark.executor.instances\", \"2\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"512m\")\n",
    "sparkConf.set(\"spark.driver.port\", \"2222\")\n",
    "sparkConf.set(\"spark.driver.blockManager.port\", \"7777\")\n",
    "sparkConf.set(\"spark.driver.host\", \"driver-service.jhub.svc.cluster.local\")\n",
    "sparkConf.set(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "sparkConf.set(\"spark.kubernetes.driver.annotation.sidecar.istio.io/inject\", \"false\")\n",
    "sparkConf.set(\"spark.kubernetes.executor.annotation.sidecar.istio.io/inject\", \"false\")\n",
    "sparkConf.set(\"spark.executor.heartbeatInterval\", \"200000\")\n",
    "sparkConf.set(\"spark.network.timeout\", \"300000\")\n",
    "sparkConf.set(\"spark.app.name\", \"spark-test-app\")\n",
    "clusterIP: None\n",
    "sc = pyspark.SparkContext(conf=sparkConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a distributed data set to test to the session\n",
    "t = sc.parallelize(range(10))\n",
    "\n",
    "# Calculate the approximate sum of values in the dataset\n",
    "r = t.sumApprox(3)\n",
    "print('Approximate sum: %s' % r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
